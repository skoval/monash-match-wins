---
title: "Predicting match results in professional tennis"
author:
- familyname: HE
  othernames: XITONG
  address: Monash University
  email: xhee0013@student.monash.edu
  correspondingauthor: true
  qualifications: 29026342
department: Department of\newline Econometrics &\newline Business Statistics
organization: ETC5543 Internship Project
bibliography: references.bib
biblio-style: authoryear-comp
linestretch: 1.5
output:
  MonashEBSTemplates::report:
    fig_caption: yes
    fig_height: 5
    fig_width: 8
    includes:
      in_header: preamble.tex
    keep_tex: yes
    number_sections: yes
    citation_package: biblatex
    toc: false
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE, message=FALSE, warning=FALSE)

library(tidyverse)
library(dplyr)
library(ggplot2)
library(here)
library(kableExtra)
library(wordcloud2)
library(ggrepel)
library(RColorBrewer)
library(scales)
library(formattable) 
library(bpcs)
library(BradleyTerry2)
library(rvest)
library(rstan)
library(bayesplot)
library(ggpubr)
```


```{r read-data}
atp_results<-readRDS(here("data/atp_results.rds"))%>%
    filter(Retired!="TRUE",Walkover!="TRUE")
wta_results<-readRDS(here("data/wta_results.rds"))%>%
    filter(Retired!="TRUE",Walkover!="TRUE")

atp_results%>%
  select(Player1,Player2,Surface,Tier)%>%
  rename(player0=Player1,player1=Player2)->atp_results
wta_results%>%
  select(Player1,Player2,Surface,Tier)%>%
  rename(player0=Player1,player1=Player2)->wta_results


```

# Introduction

In recent years, in order to meet the needs of sport coaches or media industry, the application of statistical analysis in the field of sports has developed rapidly. The ability to accurately predict the outcome of sporting matches is gaining popularity. For example, sport matches forecasting could allow media channels to provide more in-depth coverage of sporting events or allow tournament organizers to better match players' skills to provide closer, more exciting matches. Tennis is one of the appealing sports chosen in this project. The purpose of this project is to study the performance of different prediction methods in men's and women's professional tennis matches. The measure is used to build up the prediction model based on historical data in the last decay. This project examines several probabilistic models for forecasting the outcomes of professional tennis levels such as ATP or WTA matches. These models not only focus on the prediction results in the tennis matched, but also consider the head to head effect where would affect the performance in some players. In addition, the effects of surface type and the variation between players such as head-to-head effect would be addressed in the models as one of the exploratory variables and random effect variables. The models are trained and evaluated on the two historical tennis matches results of approximately 4000 tennis matches between 2010 and 2020 after filtering top 100 players. 

# The motivation of this project

The main objective of the project is to develop and evaluate different approaches for predicting the tennis match results. In addition, by considering the head to head effects which might exist in the matches, this project would investigate strategies for estimating and incorporating these matchup effects into a prediction model.


# Data description {#data}


There are two data sets such as `atp_results` and `wta_results`used on this analysis report, and the two data sets consist of approximately 36,000 matches information from 2011-01-01 to 2020-01-23 in ATP tour and WTA tour. Both of them are obtained from [GitHub skoval](https://github.com/skoval/monash-match-wins), which have similar data structures. 
The table \@ref(tab:data-structure) summarises the key information which is contained about each match in the data. The data sets also contain further side information such as player id, date of tennis tournments, Name of the match, the around in tennis match and ect. The full list is omitted as none of this additional information is used by the models in this project. So, the only four key variable were mainly used for this project. Theoretically, the full data sets should be used for data modeling but the ranking data about top 100 players in ATP or WTA will be introduced in the following section and combined them with the full data to construct the new model data which is used for the data modeling in this project report due to the system operation problem.


```{r datstructure, warning=FALSE, message=FALSE}
data <- data.frame(
  Variable = c("Surface","Player1","Player2","Tier"),
  Description = c("Match Surface","Match Winner","Match Loser","collective term referring to the group of matches or rubbers played between two teams in a team tennis even" ))

data %>%
  kable(caption = "Key match informatiom") %>%
  kable_styling(bootstrap_options = 
                c("striped", "condensed"), 
                full_width = F, 
                position = "center")
```





# Head to Head effect Analysis

Head to head means the direct competition between two players. In this project, head-to-head effect indicates that the matchup effect of two specific players meeting in the matches. This is not only to consider the player's ability in tennis skills such as the talented-levels, but more importantly to detect whether there is a certain effect between the two players such as one player might have over a specific opponent that goes beyond what their ability would predict, factors like style or psychological impact.

```{r male-win-most-of-matches,fig.cap="Most of games in male athlete "}

#Use the words cloud to briefly introduce who has won the most of matches in her/his career, which the total matches for players are above 150
atp_winner_freq<-atp_results%>%
  group_by(player0)%>%
  summarise(freq= n())%>%
  arrange(desc(freq))%>%
  filter(freq>=150)%>%ungroup

pal <- brewer.pal(8, "Dark2")

wordcloud::wordcloud(words = atp_winner_freq$player0, freq =atp_winner_freq$freq,
          scale=c(1.6,0.01),random.order=T, colors=pal, vfont=c("sans serif","plain"))

```

```{r female-win-most-of-matches,fig.cap="Most of games in female athlete }
wta_winner_freq<-wta_results%>%
  group_by(player0)%>%
  summarise(freq= n())%>%
  arrange(desc(freq))%>%
  filter(freq>=150)%>%ungroup
wordcloud::wordcloud(words = wta_winner_freq$player0, freq =wta_winner_freq$freq,
          scale=c(1.4,0.01),random.order=T, colors=pal, vfont=c("sans serif","plain"))

```


The figure \@ref(fig:male-win-most-of-matches) and the figure \@ref(fig:female-win-most-of-matches) show the male and female players who have won more than 150 games are in the last ten years. Novak Djokovic, as the current number one male player in the world rankings, has won more than 500 matches over the past last decay, and Roger Ferrer and Rafael Nadal who are the current top 10 players in the world, winning more than 450 matches. On the other hand, Caroline Wozniacki was the top 1 female players between 2010 and 2012, has won more than 370 matches in the last ten year. 

## Evaluating the head to head effect in each tier

```{r}
atp_results%>%
	dplyr::mutate(
		Player0 = ifelse(player0 <= player1, player0, player1), # Make player0 first alphabetically
		Player1 = ifelse(player0 <= player1, player1, player0)
	) ->atp_results
wta_results%>%
	dplyr::mutate(
		Player0 = ifelse(player0 <= player1, player0, player1), # Make player0 first alphabetically
		Player1 = ifelse(player0 <= player1, player1, player0)
	) ->wta_results


tier_count<-function(data,player0,player1,Tier){
  data%>%
    dplyr::group_by(player0,player1,Tier)%>%
    dplyr::summarise(n = n(),y = sum(Player0 == player0),.groups = "drop"	)
}
surface_count<-function(data,player0,player1,Surface){
  data%>%
    dplyr::group_by(player0,player1,Surface)%>%
    dplyr::summarise(n = n(),y = sum(Player0 == player0),.groups = "drop"	)
  }
```



However, tennis sports is like a pyramid, with the size of the competitive pool getting lower when the players go upward the tournament tier as the stronger players will stay until the end. In this case,if there are many cases of player-opponent matchups with a single match, this will affect the accuracy of estimations of the head-to-head effects and bring all the effects closer to zero that would be the case with a less sparse sample. Therefore, based on the table \@ref(tab:atp_tier_summary),having played more than 3 matches against an opponent is an unusually long history compared to the normal matches. In the `atp` data, there are four tier groups and ATP WorldTour 250 has most of matches records which is the lowest tier of annual men's tennis tournaments on the main ATP Tour. The player-opponent with more than 3 matches accounted for 33.28 percent in the ATP WorldTour 250, and 40.75 in the Matser1000. It is obviously that the number of matches against the same opponent will be less and less in each tier especially in ATP WorldTour 500. A similar situation occurs in `wta` data. The table \@ref(tab:wta_tier_summary) shows that less than chance of playing more than 2 or 3 games against the same opponent happened in all tiers. It is worth noting that WTA Tour will rename its tournaments in 2021 which will simplify the understanding of the structure of the tour. Therefore, the premier category become WTA 1000s and 500s and international category become WTA 250s, much like the ATP tour tournaments. In addition, 125K serier is like the challenger level in ATP which is the entry-level for tour tournaments. But from the table data, the number of matches occurred in the 125K Series is the lowest, suggesting that players at the 125K Series will not often build up substantial head-to-heads against other players on the tour. According to the data from these two tables, it indicates that head-to-head matches are infrequent and that the number of matches in each tier that involve player-opponent matchup effects in the long history is very small.

```{r atp_tier_summary,fig.cap="Matches of head to head effect on each tier in ATP"}
tier_count(atp_results,player0,player1,Tier)%>%
  group_by(Tier)%>%summarise(`match`=sum(n))%>%
  left_join(tier_count(atp_results,player0,player1,Tier)%>%
              filter(n==2)%>%group_by(Tier)%>%summarise(`match`=sum(n)),by=c('Tier'='Tier'))%>%
   left_join(tier_count(atp_results,player0,player1,Tier)%>%
              filter(n>=3)%>%group_by(Tier)%>%summarise(`match`=sum(n)),by=c('Tier'='Tier'))%>%
  rename(match=match.x,
         `match=2`=match.y,
         `match>=3`=match)%>%
  mutate(`per(match>=3)`=percent(`match>=3`/sum(`match>=3`)))->atp_tier

atp_tier_out = as.htmlwidget(formattable(atp_tier,
            list(`per(match>=3)` = color_bar("#BDD9EC"))))
                # `per(match=2)` = color_bar("#FA614B") )))
atp_tier_out $dependencies = c(atp_tier_out $dependencies, htmlwidgets:::widget_dependencies("sparkline", "sparkline"))
atp_tier_out 
```

```{r wta_tier_summary,fig.cap="Matches of head to head effect on each tier in WTA"}
tier_count(wta_results,player0,player1,Tier)%>%
  group_by(Tier)%>%summarise(`match`=sum(n))%>%
  left_join(tier_count(wta_results,player0,player1,Tier)%>%
              filter(n==2)%>%group_by(Tier)%>%summarise(`match`=sum(n)),by=c('Tier'='Tier'))%>%
   left_join(tier_count(wta_results,player0,player1,Tier)%>%
              filter(n>=3)%>%group_by(Tier)%>%summarise(`match`=sum(n)),by=c('Tier'='Tier'))%>%
  rename(match=match.x,
         `match=2`=match.y,
         `match>=3`=match)%>%
  mutate(`per(match>=3)`=percent(`match>=3`/sum(`match>=3`)))->wta_tier

wta_tier_out  = as.htmlwidget(formattable(wta_tier,
            list(`per(match>=3)` = color_bar("#BDD9EC"))))
                # `per(match=2)` = color_bar("#FA614B") )))
wta_tier_out$dependencies = c(wta_tier_out$dependencies, htmlwidgets:::widget_dependencies("sparkline", "sparkline"))
wta_tier_out
```

## Evaluating the H2H effect in each surface

Similarly, the table \@ref(tab:atp_surface_summary) and table \@ref(tab:awta_surface_summary) represent the number of tennis matches occurred in different surface type in the last decay. Obviously, the majority of matches, and even matchups more than three times, take place on hard courts, where movement tends to be medium to fast because the court absorbs little energy and players are able to use a variety of spins during the match. In addition, Clay court is the second highest frequency playing surface and it examines the return ability of players as the balls bounce relatively high and lose a lot of initial velocity on contact with the water. Moreover, the number of matches for more than three times with same opponent are small in these two table, suggesting that the number of matches in head to head effect is relatively small even in ten years record.

```{r atp_surface_summary,fig.cap="Matches of head to head effect on three types of surface in ATP"}

#calculate the percentage of h2h matches in each surface for atp results
surface_count(atp_results,player0,player1,Surface)%>%
  group_by(Surface)%>%summarise(`match`=sum(n))%>%
  left_join(surface_count(atp_results,player0,player1,Surface)%>%
              filter(n==2)%>%group_by(Surface)%>%summarise(`match`=sum(n)),by=c('Surface'='Surface'))%>%
   left_join(surface_count(atp_results,player0,player1,Surface)%>%
              filter(n>=3)%>%group_by(Surface)%>%summarise(`match`=sum(n)),by=c('Surface'='Surface'))%>%
  rename(match=match.x,
         `match=2`=match.y,
         `match>=3`=match)%>%
  mutate(`per(match>=3)`=percent(`match>=3`/sum(`match>=3`)))->atp_surface

atp_surface_out = as.htmlwidget(formattable(atp_surface,
            list(`per(match>=3)` = color_bar("#BDD9EC"))))
                # `per(match=2)` = color_bar("#FA614B") )))
atp_surface_out $dependencies = c(atp_surface_out $dependencies, htmlwidgets:::widget_dependencies("sparkline", "sparkline"))
atp_surface_out
```

```{r wta_surface_summary,fig.cap="Matches of head to head effect on three types of surface in WTA"}

#calculate the percentage of h2h matches in each surface for atp results
surface_count(wta_results,player0,player1,Surface)%>%
  group_by(Surface)%>%summarise(`match`=sum(n))%>%
  left_join(surface_count(wta_results,player0,player1,Surface)%>%
              filter(n==2)%>%group_by(Surface)%>%summarise(`match=2`=sum(n,na.rm=TRUE)),by=c('Surface'='Surface'))%>%
   left_join(surface_count(wta_results,player0,player1,Surface)%>%
              filter(n>=3)%>%group_by(Surface)%>%summarise(`match>=3`=sum(n,na.rm=TRUE)),by=c('Surface'='Surface'))->wta_surface
wta_surface[is.na(wta_surface)] = 0
wta_surface%>%
  mutate(`per(match>=3)`=percent(`match>=3`/sum(`match>=3`)))->wta_surface

wta_surface_out = as.htmlwidget(formattable(wta_surface,
            list(`per(match>=3)` = color_bar("#BDD9EC"))))
                # `per(match=2)` = color_bar("#FA614B") )))
wta_surface_out $dependencies = c(wta_surface_out $dependencies, htmlwidgets:::widget_dependencies("sparkline", "sparkline"))
wta_surface_out
```

In the following section, a variety of prediction methods will be introduced formally, and evaluated the estimates for parameters of the model and model performance.


# Modeling section

The model analysis was conducted to identify different forecasting methods for tennis match result. The majority of approaches to tennis match prediction fall into two categories: simple pair comparison models and Bayesian Paired Comparison models in Stan.

## Pairwise Comparison Models

Pairwise comparison is the process of comparing entities in pairs to determine which one has a better chance of winning. One of the famous and more effective method for establishing pairwise comparison is Bradley Terry Model[@bradley1952rank], applying in the contest between two players in tennis[@mchale2011bradley].

Let $$y_{ij,t}$$ be the outcome of a tennis match that is played between player i and player j at time t. We assume that we have information about K different players over a time period of length n, i.e. i, j =1.... ,K and t =1..., n. The outcome $${y_{ij,t} =1}$$ if player i wins the match at time t whereas the outcome $${y_{ij,t} =0}$$  if player j wins the match at time t. Therefore, the outcomes about $$y_{ij,t}$$ are binary response value.

The conditional probability that $${y_{ij,t} =1}$$is given by 
$$P_{ij,t}=P(y_{ij,t}=1|\delta_{ij,t})=\frac{exp(\delta_{ij,t})}{1+exp(\delta_{ij,t})}$$;$$\delta_{ij,t}=\lambda_{i,j}-\lambda_{j,t}$$
where$$\lambda_{i,t}$$ represents the skill level of player i at time t and $$\lambda_{j,t}$$ represents the skill level of player j at time t. The conditional probability of $${y_{ij,t} =0}$$ is instead equal to$$1-P_{ij,t}$$.

On the other hand, this model can be alternatively expressed in the following logit-linear way, which can be reduce the model to logistics regression on pairs of individuals:
$$\mathrm{P}(\left[ i \mbox{ beats } j \right]=logit(P(i>j))=log(\frac{P(i>j)}{1-P(i>j)})=\lambda_{i}-\lambda_{j}$$
where $$\lambda_{i}$$=log$$\alpha_{i}$$ for all i and is the respective skill parameter of the players. Optimization can be used to jointly solve for skills parameters of all players based on a fixed period of historical results. Match winning probabilities can then be derived based on the same i.i.d(independent identifying distributed)[@klaassen2001points] assumption used in point models. Therefore, based on the IID assumption for all contests,the parameters $$\lambda_{i}$$ can be estimated by maximum likelihood using `BradleyTerry2` package[@turner2012bradley] for generalized linear models. 

The `BradleyTerry2` package provides a more flexible user interface to allow a wider range of models to be fitted in the data and allows the inclusion of simple random effects, where the $$ \lambda_{i}$$ can be related to explanatory variable via a linear predictor of the form:
$$\lambda_{i}=\sum_{r=1}^{p}{\beta_{r}x_{ir}+U_{i}}$$

The inclusion of the prediction error $$U_i$$ allows for variability between players with equal covariate values and induces correlation between comparisons with a common player. 


## Bayesian Paired Comparison models in Stan

**Simple Bradley Terry model: **

Bayesian inferences are based on a posterior probability density distribution (further referred to as the posterior) regarding the parameters, given the data collected. This allows for a more intuitive interpretation of parameters uncertainty. Therefore, the Bayesian model can be broken down as consisting of:

* Observed variables: The tennis matches outcomes are given. A single outcome will be given the notation r and a set of outcomes D.

* prior probability: P(w). A standard normal prior is used in this project($$w_{std} \sim N(0,1)$$;$$w \sim N(0,w_{std}^2)$$

The future outcomes can be predicted based on the relationship $$P(r|w)$$ if given the parameters of the model. However,since the parameters are unknown, the future value become inferred based on the historical data. For some data D, on a set of n outcomes, the posterior probability of the given model parameters can be expressed as:
$$P(w|D)=\frac{P(D|w)P(w)}{P(D)} \propto P(D|w)P(w)$$
where P(D|w) is the likelihood of the model given the data and P(D) is marginal likelihood of the model found through normalisation. Under the assumption that outcomes are independent identified distributed, the likelihood can be expressed as:
$$P(D|w)=\prod_{i = 1}^{N} P(r^i|w)$$ 

Moreover, for the prediction with new match $$r^{n+1}$$,it can be made by taking the expectation of $$P(r^{n+1}|w)$$ with respect to the posterior distribution P(w|D). One of the common method to achieve the predicted value is used an approximate inference technique to approximate the full posterior distribution. In this case, it refers to Bayesian approach. 

Applying Bayesian method[@peterspredicting] in Bradley Terry Model, the extension formula is shown as below:

$$\mathrm{P}(\left[ i \mbox{ beats } j \right])=P(r_{ij}=1|\lambda_{i},\lambda_{j})=\frac{exp(\lambda_{i})}{exp(\lambda_{i})+exp(\lambda_{j})}=\frac{1}{1+e^{-(\lambda_{i}-\lambda_{j})}}=\sigma(\lambda_{i}-\lambda_{j}) $$

where$$r_{ij}=1$$ indicates a win for player i against player j,$$\lambda_{i}$$ and $$\lambda_{j}$$ are the player skills which are the parameters of the model, and $$\sigma$$ is the logistic sigmoid function: $$\frac{1}{1+e^{-x}}$$. 

For the some of data consisting of a set of match outcomes $$D={r^1,r^2...r^n}$$ for a set of players $$M ={1,2,...,m}$$ with ability $$\lambda={\lambda_{1},\lambda_{2},...,\lambda_{m}}$$,the likelihood of the model given the data can be expressed as:
$$P(D|\lambda)=\prod_{i = 1}^{N} \sigma(\lambda_{a}^i-\lambda_{b}^i)$$ 

In this project, the $$\lambda$$ will be estimated as the prior probability with standard normal distribution ($$\lambda_{std} \sim N(0,1)$$;$$\lambda \sim N(0,\lambda_{std}^2)$$ and then added the observed match outcomes constantly to evaluate if the model strengthens or weakens the prior probability, so that the estimated posterior probability which will bet closer to actual value. After revising the posterior probabilities, the next match predictive outcome $$P(r^{n+1}_{ij}=1|w)$$ will be inferred as: $$\sigma(\lambda_{i}-\lambda_{j})$$ through posterior predictive distribution with Maximum a posteriori estimation(MAP) if given the previous matches data $$r^n_{ij}$$

**Mixed effect model in Stain (Surface random effect ): **

Böckenholt (2001) decomposed the paired comparison model into fixed and a random effect components. The random effects component estimates the subject variation (given S subjects) in each item, while the fixed effect component such as $$\lambda_{i,s}$$ and $$\lambda_{j,s}$$ estimates the average log ability of the player. The random effects term is represented by $$U_{i,s}$$, where i refers to the player being judged and s to the subject. The Bayesian Bradley-Terry model with random effects can be represented as:
$$\mathrm{Pr}\left[ i \mbox{ beats } j \right]=\frac{exp(\lambda_{i,s})}{exp(\lambda_{i,s})+exp(\lambda_{j,s})}$$;
$$\lambda_{i,s}=\lambda_{i}+U_{i,s}$$;

$$y_{ij}\sim Bernoulli(\mathrm{P}\left[ i \mbox{ beats } j \right])$$;
$$ \lambda_{i} \sim N(0,\sigma_{\lambda}^2),[Prior]$$;
$$ U_{i,s} \sim N(0,U_{std}^2),[Prior]$$;
$$ U_{std} \sim N(0,\sigma_{U}^2),[Prior]$$

In this case, $$s$$ represents different types of surface so $$U_{std}$$ represents the standard deviation in the random effects and the difference between subjects. Therefore, the surface variable should be the random intercept as the grouped variables to evaluate the ability of each players within different surfaces. By doing this way, added the surface as a benchmark to represent the matches in which each pair players on different field. Moreover,the parameters $$ \lambda_{i}$$ can be used to rank the different players. However, in the Bayesian framework, a single measure is not obtained but rather a posterior distribution of the parameters $$ \lambda_{i}$$. By sampling from the posterior distribution of the log-abilities of the players, it is possible to create a posterior distribution of the ranks of the players, which helps to evaluate the uncertainty in the ranking system.


# Impelementation

This section discusses the implementation of three different prediction models and is structured as follows:
- Data re-preparation: briefly discusses the new model data about ranking data with top 100 players.
- Model process: mainly introduces the process of modeling in each prediction model. 
- Model output analysis: discusses the findings and results from the models.

## Data re-preparation

For avoiding the technical issue such as the system crush, overload and time consumption, a subset data with selecting top 100 players for ATP and WTA to build up the model efficiently instead of using the full datasets with ATP and WTA matches record. Therefore, `atp_ranking` and `wta_ranking` were collected from the official websites, atpworldtour.com and wtatennis.com respectively, with the rankings of the top 100 women and 100 men and they joined with the full dataset so the players were limited in the ranking of top 100 in both male and female for the final model data and it will be used for whole modeling parts.


```{r read-tennis-ranking}
library(rvest)
atp_html <- read_html(here::here("data/ATP_Tennis.html"))
atp_rankings <- html_node(atp_html, "table") %>% html_table(fill=TRUE) 
# There is only one table in page so use html_node rather than html_nodes
atp_rankings <- atp_rankings %>% 
  janitor::remove_empty() %>% 
  dplyr::as_tibble()



wta_html <- read_html(here::here("data/WTA_Tennis.html"))


wta_rankings <- html_node(wta_html, "table") %>% html_table(fill=TRUE) 
wta_rankings <- wta_rankings %>% 
  janitor::remove_empty() %>% 
  as_tibble()%>%
  head(100)

```

```{r subset-top-100-players}
atp_results%>%
 select(player0,player1,Surface,Player0,Player1) %>%  
  filter(player0%in%atp_rankings$Player & player1%in%atp_rankings$Player)->atp_top_100

wta_results%>%
 select(player0,player1,Surface,Player0,Player1) %>%  
  filter(player0%in%wta_rankings$PLAYER & player1%in%wta_rankings$PLAYER)->wta_top_100
h2h_count<-function(data,player0,player1){
  data%>%
    group_by(Player0, Player1) %>%
	dplyr::summarise(	n = n(),y = sum(Player0 == player0),.groups = "drop")
}

```

```{r construct-clean-datasets}
# tidy up new matches data and convert the two factors for players into same level in terms of building the model
h2h_count(atp_top_100,player0,player1)%>%
  rename(total_count=n,
         p0_count=y)%>%
  mutate(p1_count=total_count-p0_count,
          Player0 = factor(Player0, levels = unique(c(Player0, Player1))),
         Player1= factor(Player1, levels = levels(Player0)))->atp_match

h2h_count(wta_top_100,player0,player1)%>%
  rename(total_count=n,
         p0_count=y)%>%
  mutate(p1_count=total_count-p0_count,
          Player0 = factor(Player0, levels = unique(c(Player0, Player1))),
         Player1= factor(Player1, levels = levels(Player0)))->wta_match
```


## Bradley Terry Model Evaluation


```{r simple-BT-model}
#the coefficients are maximum likelihood estimates of lambda n with lambda1( the log-ability for Adrian Mannarino) set to zero as identifying convention

#~player specifies the model for player ability, in this case it stands for ‘tennis capability’ 

atp_bt<-BTm(cbind(p0_count,p1_count),Player0,Player1,~Player,id="Player",data=atp_match)
wta_bt<-BTm(cbind(p0_count,p1_count),Player0,Player1,~Player,id="Player",data=wta_match)

```

**Modeling process:**
- `BTm` function: constructs the Bradley Terry model with the matrix of p0_count and p1_count from the top 100 players data

- `BTabilities` function:  computes the ability of each player from the model objects against with the baseline player.

**Model output analysis:**

* Ability graph interpretation:

From the table \@ref(tab:estimated-ability), Adrian Mannarino and Ajla Tomljanovic became the baseline against with other players in the ATP and WTA data as their ability are 0. In the ATP data,Novak Djokovic,Rafael Nadal and Roger Federer have the highest estimated ability compared with the Adrian Mannarino. All three of them have played and won most of matches and their ranking almost maintain in the top 10 of the world on average, indicating that their tennis level are higher than other players. On the contrary, Lorenzo Musetti and Sebastian Korda have the lowest estimated ability and one of reason for that they have only played one game and even lost in that match,so their ability are estimated quite lower. 

Similarly, in the WTA model,Serena Williams have the highest estimated tennis skill whereas Clara Tauson have the lowest estimated tennis ability compared with Ajla. That could be caused by the fact that Serena won the most of matches like more than 50 matches based on the data and Clara only had played two matches but she lost both of them. 


```{r estimated-ability,fig.cap="The estimated ability of different tennis players"}
# construct the coefficient data frame and read the coeffienct in convenient way
atp_abilities <- BTabilities(atp_bt) # Matrix of ability and StdErr

atp_abilities <- data.frame(
  Player = rownames(atp_abilities),
  Ability = atp_abilities[,1],
  SE = atp_abilities[,2]
)

atp_abilities$Player <- factor(atp_abilities$Player, 
                        levels = atp_abilities$Player[order(atp_abilities$Ability)],
                        order = T)

wta_abilities <- BTabilities(wta_bt) # Matrix of ability and StdErr

wta_abilities <- data.frame(
  Player = rownames(wta_abilities),
  Ability = wta_abilities[,1],
  SE = wta_abilities[,2]
)

wta_abilities$Player <- factor(wta_abilities$Player, 
                        levels = wta_abilities$Player[order(wta_abilities$Ability)],
                        order = T)

atp_abilities%>%
  DT::datatable(options = list(pageLength = 10),filter = 'top', caption = 'The estimated ability for ATP data')

wta_abilities%>%
   DT::datatable(options = list(pageLength = 10),filter = 'top', caption = 'The estimated ability for WTA data')
  
  # DT::datatable(options = list(pageLength = 10),filter = 'top', rownames = FALSE,caption = htmltools::tags$caption(
  #   style = 'caption-side: bottom; text-align: center;',
  #   'Table 2: ', htmltools::em('The estimated ability for WTA data')
  # ))
```



### Bayesian Paired Comparison models in Stan

#### Bradley Terry model with head-to-head effect

**Modeling process:**

-`model_stan_data`:construct the stan model data with the total number of matches and the number of matches of player0 winning in each pair of players

- `bpc_h2h_pred.stan`: is the model script file. Instead of only using simple Bradley Terry model with bernoulli distribution in a single match,the Stan model data collapse the matches between every pair of players so it had been became the binomial distribution, which is structured as: $$y \sim binomial(n,p)$$ 

The main parameters are used in the stan model:
  *n: is the N trials 
  *y: is the number of success which is the number of times that player1 has won the match in this case. 
  *`lambda`: is the latent variable, representing the ability of a player and had estimated from standard normal distribution. 
  *$$h2hz_{player_i,player_j}$$: is a matrix which assigns the upper triangular values following standard normal distribution and lower triangular values following normal distribution but it has to be closer to zero which is the effective zero assignment.
  *$$h2h_{player_i,player_j}$$: is a matrix which assigns the upper triangular values using draws around a shared normal distribution. The lower triangular are the same effects of opposite sign. So basically there is a shared effect for player i, j but it adds or subtracts depending on the order of player and which player we are predicting the chance of a win for. 
  * `p1_win`: is the probability of player1 win with considering the head-to-head effects between each pair of player. In addition, based on the Bradley Terry Model, it has been used logistics function to evaluate the probability of player1 win($$log_odd_players$$) on the logit scale which is mapped $$(0,1) \to R$$, so the inverse logistics function should be used to transform the $$log_odd_players$$ to real probability of player1 win which is mapp $$R \to (0,1)$$ and the final structure for $$p1_{win}$$ is shown as below:
$$\frac{e^{\lambda_{player1}-\lambda_{player0}+h2h_{player1,player0}}}{1+e^{\lambda_{player1}-\lambda_{player0}+h2h_{player1,player0}}}$$

  *`generated quantities`: created a new vector for predictive value via binomial distribution
  
- `vb` function: is used variational inference for finding optimal posterior distribution. In this case,using VB testing for examining the result whether the model construction and diagnostics is reasonable approximation or not. It can also minimize the difference between actual distribution and approximation distribution and reduce the time consumption, which is a more effective and less uncertain method for checking the Stan model correctly.
- `sampling` function: computes posterior samples via MCMC(Markov Chain Monte Carlo) method given a model previously compiled from `stan_model` (bpc_h2h_pred.stan). In this case, it is more reliable way for final inferences to find the posterior probability.



```{r stan-data-function}
#set up the stan model data for atp and wta
make_stan_data <- function(data, win, n, player0, player1){
  
  players <- unique(c(data[[player0]], data[[player1]]))
  index <- order(players)
  names(index) <- players
  
  model_data  = list(
    index = index,
    y = data[[win]],
    n = data[[n]],
    player0_indexes = index[data$player0],
    player1_indexes = index[data$player1],
    N_total = nrow(data),
    N_players = max(index)
  )
}


atp_stan_data<-atp_match%>%
  rename(n=total_count,y=p1_count)%>%
  mutate(player0=as.character(Player0),
         player1=as.character(Player1))%>%
  select(player0,player1,n,y)

wta_stan_data<-wta_match%>%
  rename(n=total_count,y=p1_count)%>%
  mutate(player0=as.character(Player0),
         player1=as.character(Player1))%>%
  select(player0,player1,n,y)


model_data_atp <- make_stan_data(atp_stan_data, "y", "n", "player0", "player1")
model_data_wta <- make_stan_data(wta_stan_data, "y", "n", "player0", "player1")

```

```{r stan-model,eval=FALSE}

model <- rstan::stan_model("bpc_h2h_pred.stan")

# VB for model testing/development
atp_fit_model <- rstan::vb(model, 
                           data = model_data_atp,
                           tol_rel_obj = 0.001)
wta_fit_model <- rstan::vb(model, 
                           data = model_data_wta,
                           tol_rel_obj = 0.001)
# Use Sampling for final inference
atp_stan <- rstan::sampling(model, 
                           data = model_data_atp)
#saveRDS(wta_stan,"wta_stan.rds")
wta_stan <- rstan::sampling(model, 
                           data = model_data_wta)

#construct the clean coefficient from the output of stan-model
atp_fit_summary <- summary(atp_stan)$summary %>% 
  as.data.frame() %>% 
  mutate(variable = rownames(.)) %>% 
  select(variable, everything()) %>% 
  as_data_frame()
#write_csv(atp_fit_summary,"atp_stan.csv")

wta_fit_summary <- summary(wta_stan)$summary %>% 
  as.data.frame() %>% 
  mutate(variable = rownames(.)) %>% 
  select(variable, everything()) %>% 
  as_data_frame()
#write_csv(wta_fit_summary,"wta_stan.csv")
```

*Model output analysis:*

**MCMC Parameter diagnostics:**

By default the sampling method runs 4 Markov chains of Hamiltonian Monte Carlo in parallel, each of those chains proceeds with 1000 warmup iterations and 1000 sampling iterations, totaling 4000 sampling iterations available for diagnostics and analysis.

To examine the model fitting, the MCMC parameter diagnostics should be built up after extracting summary statistics on each model parameter.

- 1. n_eff: the effective sample size
  *`n_eff` measures the effective sample size of that particular parameter which is the sum of the effectively independent sampling iterations across all chains(from a total 4000). The smaller `n_eff`, the greater the uncertainty associated with the corresponding parameter. If the ratio (`n_eff`/N) less than 0.001,indicating that the estimators are biased and significantly overestimate the true effective sample size(@gelman1992inference). Based on the figure \@ref(fig:check-neff),the distribution of ratio in two Stan models shows most of value are bigger than 0.5, suggesting that most of estimated parameter have better precision and there are no indications of problems in estimates of the effective sample size.
  
- 2. Rhat: the potential scale reduction statistic
  *`Rhat` statistic is roughly the ratio of the variance of a parameter when the data is pooled across all of the chains to the within-chain variance so it can helps tell us whether these parameters are so poorly sampled and measures the extent to which chains are reaching different conclusions. The Rhat should be in the range of 0.9 to 1.05 as the more idiosyncratically the chains behave if the Rhat value is far away from 1 (@vehtari2021rank).  Figure \@ref(fig:check-rhat) displays the distribution of Rhat value in two Stan models and most of Rhat value are close to 1, implying that all chains have been converged to the same systematic behavior for a given parameter.
  
```{r check-neff,fig.cap="Evalute effective sample size in stan model"}

#constructed the summary statistics for atp or wta stan model
atp_fit<-read.csv(here("Match-prediction/atp_stan.csv"))
wta_fit<-read.csv(here("Match-prediction/wta_stan.csv"))

N<-4000
atp_neff_ratios<-atp_fit$n_eff/N
wta_neff_ratios<-wta_fit$n_eff/N

neff1<-mcmc_neff_hist(atp_neff_ratios,binwidth =0.1)+
  ggtitle("ATP stan model")

neff2<-mcmc_neff_hist(atp_neff_ratios,binwidth =0.1)+
ggtitle("WTA stan model")


ggarrange(neff1,neff2, common.legend = TRUE, legend="bottom",font.label = list(size=5,face="plain"))

```

```{r check-rhat,fig.cap="Evalute potential scale reduction statistic in stan model"}

atp_rhats<-atp_fit$Rhat
wta_rhats<-wta_fit$Rhat
rhat1<-mcmc_rhat_hist(atp_rhats,binwidth = 0.0005)+
  ggtitle("ATP stan model")

rhat2<-mcmc_rhat_hist(wta_rhats,binwidth = 0.001)+
  ggtitle("WTA stan model")

ggarrange(rhat1,rhat2, common.legend = TRUE, legend="bottom",font.label = list(size=5,face="plain"))
```



**Head-to-head effect evaluation:** 

- 1. H2H effect parameter distributions:

Figure \@ref(fig:check-h2h) represents the distribution of head-to-head effects are concentrated at 0 in two Stan models. The variation in h2h effects between the different players in the ATP model data was about 34%, which is higher than the variation with 17% in the WTA model data.

```{r check-h2h,fig.cap="The distribution of head-to-head effects in stan model"}
# check the h2h effect whether it is concentrated at 0
h2h1<-atp_fit %>% 
  filter(str_detect(variable,"h2h\\["))%>%
  summarise(mean=mean(mean),`2.5%`=mean(`X2.5.`),`97.5%`=mean(`X97.5.`),`25%`=mean(`X25.`),`75%`=mean(`X75.`))%>%
  mutate(variable=paste("h2h"))%>%
  ggplot() + 
  geom_linerange(aes(variable, ymin = `2.5%`,ymax = `97.5%`)) + 
  geom_crossbar(aes(variable, mean, ymin = `25%`, ymax = `75%`), fill= 'grey') +
  ggtitle("ATP stan model")


h2h2<-wta_fit %>% 
  filter(str_detect(variable,"h2h\\["))%>%
  summarise(mean=mean(mean),`2.5%`=mean(`X2.5.`),`97.5%`=mean(`X97.5.`),`25%`=mean(`X25.`),`75%`=mean(`X75.`))%>%
  mutate(variable=paste("h2h"))%>%
  ggplot() + 
  geom_linerange(aes(variable, ymin = `2.5%`,ymax = `97.5%`)) + 
  geom_crossbar(aes(variable, mean, ymin = `25%`, ymax = `75%`), fill= 'grey') +
    ggtitle("WTA stan model")

ggarrange(h2h1,h2h2,font.label = list(size=5,face="plain"))
```

- 2. H2H effect in ATP data:

By filtering the negative mean value of h2h effects which is corresponded to a player who is disadvantaged or has lower win chance against with their opponent, the table \@ref(tab:h2h-atp) shows the head-to-head effects in different pair and ranked players. The largest negative is -0.27 between Dominic Thiem and David Goffin, where Dominic has lower win chance in their matches. On the other hand, there are also some interesting facts, for example Novak Djokovic and Daniil Medvedev are the world's No. 1 and No. 2 tennis players, but they have a greater chance to lose the match in the face of Nick Kyrgios and Lucas Pouille. Generally speaking, the higher ranked players have a better level of tennis skill or more talented whereas they are also likely to suffer failure when facing specific opponents,like Dominic Thiem against Kevin Anderson, who are more than 90 places apart in the rankings and the h2h effect with -0.177 shows Dominic has disadvantage with Kevin. It is obviously that Roberto Bautista Agut, Adrian Mannarino,Jeremy Chardy and Borna Coric have all appeared twice in the top 10 head-to-head effects, with Jeremy being the only person to be favored whereas Roberto being the only one to be disadvantage in both cases.

```{r h2h-atp,fig.cap="Head-to-head effect for each pair of players in ATP data"}
atp_players <- unique(c(atp_stan_data$player0, atp_stan_data$player1))
atp_index <- order(atp_players)
cbind(atp_players,atp_index)%>%
  as.data.frame()->atp_players
atp_stan_data%>%
  left_join(atp_players,by=c("player0"="atp_players"))%>%
  left_join(atp_players,by=c("player1"="atp_players"))%>%
  rename(player0_id=atp_index.x,
         player1_id=atp_index.y)->atp_stan_data

atp_fit%>%
  filter(str_detect(variable,"h2h\\["))%>%
  #filter(mean>0.1|mean<(-0.1))%>%
  arrange(desc(-mean))%>%
  separate(variable,c("h2h","id0","id1"))%>%
  select(id0,id1,mean)%>%
  left_join(atp_players,by=c("id0"="atp_index"))%>%
  left_join(atp_players,by=c("id1"="atp_index"))%>%
  rename(player0=atp_players.x,
         player1=atp_players.y)%>%
  left_join(atp_rankings%>%
              select(Ranking,Player),by=c("player0"="Player"))%>%
   left_join(atp_rankings%>%
              select(Ranking,Player),by=c("player1"="Player"))%>%
  rename(player0_rank=Ranking.x,
         player1_rank=Ranking.y)->atp_h2h
atp_h2h%>%
  filter(mean<0)%>%
  select(player0_rank,player1_rank,player0,player1,mean)%>%
  DT::datatable(options = list(pageLength = 10),filter = 'top')
atp_h2h%>%
  filter(mean<0)%>%
  select(id0,id1,player0,player1,mean,player0_rank,player1_rank)%>%
  arrange(desc(-mean))
```



```{r h2h-wta}
wta_players <- unique(c(wta_stan$player0, wta_stan$player1))
wta_index <- order(wta_players)
cbind(wta_players,wta_index)%>%
  as.data.frame()->wta_players
wta_stan%>%
  left_join(wta_players,by=c("player0"="wta_players"))%>%
  left_join(wta_players,by=c("player1"="wta_players"))%>%
  rename(player0_id=wta_index.x,
         player1_id=wta_index.y)->wta_stan

wta_fit%>%
  filter(str_detect(variable,"h2h\\["))%>%
  arrange(desc(-mean))%>%
  separate(variable,c("h2h","id0","id1"))%>%
  select(id0,id1,mean)%>%
  left_join(wta_players,by=c("id0"="wta_index"))%>%
  left_join(wta_players,by=c("id1"="wta_index"))%>%
  rename(player0=wta_players.x,
         player1=wta_players.y)%>%
  left_join(wta_rankings%>%
              select(RANK,PLAYER),by=c("player0"="PLAYER"))%>%
   left_join(wta_rankings%>%
              select(RANK,PLAYER),by=c("player1"="PLAYER"))%>%
  rename(player0_rank=RANK.x,
         player1_rank=RANK.y)->wta_h2h
wta_h2h%>%
  filter(player0_rank<player1_rank&mean<0)%>%
  select(player0_rank,player1_rank,player0,player1,mean)%>%
  arrange(desc(-mean))%>%
  DT::datatable(options = list(pageLength = 10),filter = 'top')
wta_h2h%>%
  filter(mean<0)%>%
  select(id0,id1,player0,player1,mean)%>%
  arrange(desc(-mean))
```

Compared with `atp_fit`, the smallest estimated values of h2h effects in the `wta_fit` is -0.0867 which is not quite lower. In the first 10 pair of players, the rank difference between Petra Kvitova and Madison Brengle is the largest and the estimated h2h effect is only -0.072, suggesting Petra Kvitova has lower chances to win Madison. Also, it is interesting to see several players occurr multiple times in the top 10 matchup effects. Barbora Strycova and Heather Watson occurred twice among the 10 biggest head-to-head effects while Caroline Garcia occurred three times. Moreover, Barbora with her head-to-head over Caroline or Johanna Konta, and Heather with her head-to-head over Sloane Stephens or Caroline are the only two players to be favoured. Another things to be noticed that Caroline was disadvantage with Barbora and Heather but she has higher probability to win Victoria Azarenka whose rank is higher.


```{r}
atp_stan%>%
  select(player0,player1,n,y)%>%
  rename(p0_count=y,total_count=n)%>%
  mutate(p0_pro=p0_count/total_count)%>%
  cbind(atp_fit%>%
  filter(str_detect(variable,"y_pred"))%>%
  select(mean))%>%
    mutate(y_pred=mean/total_count)->atp_stan_pred


bins(atp_stan_pred)->atp_stan_bins

bin_freq(atp_stan_bins)->atp_stan_freq

atp_stan_freq%>%
  left_join(atp_stan_bins%>%
  group_by(bins)%>%
  summarise(mean_act=sum(p0_count)/sum(total_count)))->atp_stan_cali


ggplot(atp_stan_cali,aes(mean_act,mean_pred))+
  geom_line()+
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  coord_cartesian(xlim = c(0, 1), ylim = c(0, 1)) +
  theme_bw() 

```


**Mixed effect model in Stain (Surface random effect ): **



```{r random-effect-model,eval=FALSE}
atp_top_100%>%
  select(player0,player1,Surface)%>%
  mutate(y=as.numeric(0))->atp_top_surface

wta_top_100%>%select(player0,player1,Surface)%>%
  mutate(y=as.numeric(0))->wta_top_surface

atp_random <- bpc(data = atp_top_surface,
          player0 = 'player0',
          player1 = 'player1',
          result_column = 'y',
          model_type = 'bt-U',
         cluster = 'Surface',
          solve_ties = 'none', #there are no ties
          priors = list(prior_lambda_std = 2.0,prior_U1_std = 10.0),
            iter = 3000)

wta_random <- bpc(data = wta_top_surface,
          player0 = 'player0',
          player1 = 'player1',
          result_column = 'y',
          model_type = 'bt-U',
         cluster = 'Surface',
          solve_ties = 'none', #there are no ties
          priors = list(prior_lambda_std = 2.0,prior_U1_std = 10.0),
            iter = 3000)
# write_csv(atp_random$hpdi,"atp_hpi.csv")
# write_csv(atp_random$lookup_table,"atp_lookup_table.csv")
#saveRDS(wta_random,"wta_random.rds")
```


```{r coefficient-atp-random}
#constructed the summary statstics of bpc function in atp data
atp_hpi<-read.csv(here("data/atp_hpi.csv"))
atp_lookup<-read.csv(here("data/atp_lookup_table.csv"))


# check the ability of each players
# A higher lambda indicates a higher team ability
atp_lookup%>%
  left_join(atp_rankings%>%
              select(Player,Ranking),by=c("Names"="Player"))%>%
  right_join(atp_hpi%>%
  filter(str_detect(Parameter,"lambda"))%>%
  separate(Parameter,c("lambda","index"))%>%
    mutate(index=as.numeric(index)),by=c("Index"="index"))%>%
  arrange(desc(Mean))


# check the random effect coefficient with different players in hard surface
# the effect of a particular cluster in a particular team ability.

atp_lookup%>%
  left_join(atp_rankings%>%
              select(Player,Ranking),by=c("Names"="Player"))%>%
  right_join(atp_hpi%>%
  filter(str_detect(Parameter,"U1\\["))%>%
  separate(Parameter,c("U1","index","cluster"))%>%
    mutate(index=as.numeric(index))%>%
  filter(cluster=="1"),by=c("Index"="index"))%>%
  arrange(desc(Mean))

# check the random effect coefficient with different players in clay surface
atp_lookup%>%
  left_join(atp_rankings%>%
              select(Player,Ranking),by=c("Names"="Player"))%>%
  right_join(atp_hpi%>%
  filter(str_detect(Parameter,"U1\\["))%>%
  separate(Parameter,c("U1","index","cluster"))%>%
    mutate(index=as.numeric(index))%>%
  filter(cluster=="2"),by=c("Index"="index"))%>%
  arrange(desc(Mean))

# check the random effect coefficient with different players in grass surface
atp_lookup%>%
  left_join(atp_rankings%>%
              select(Player,Ranking),by=c("Names"="Player"))%>%
  right_join(atp_hpi%>%
  filter(str_detect(Parameter,"U1\\["))%>%
  separate(Parameter,c("U1","index","cluster"))%>%
    mutate(index=as.numeric(index))%>%
  filter(cluster=="3"),by=c("Index"="index"))%>%
  arrange(desc(Mean))
```

From the outputs above,it shows the ability of different players and the effect of the particular surface for player's ability. Thus, Novak Djokovic, Rafael Nadal and Roger Federer have the highest lambda value,indicating that these three players have the advanced the tennis skills compared the rest of players. Instead of only evaluating the ability of different players,the random effect with surface type are included in the model for analyzing the effect of different surface types for a player's ability. So there are three clusters such as cluster 1, cluster 2 and cluster 3, representing the hard, clay,and grass surface. In general, Daniil Medvedev has the best tennis ability in the hard court and Dominic Thiem has more advantage in the clay court whereas Marin Cilic is better playing at grass court.

```{r surface-predicted-value,eval=FALSE}
new_atp<-atp_surface%>%
  dplyr::select(player0,player1,Surface)

predict(atp_random,type="response",newdata = new_atp)%>%
  as_tibble()->atp_pred
cbind(new_atp,colMeans(dplyr::select(df, starts_with('y_pred')))%>%
  as_tibble())->atp_surface_pred
#write_csv(atp_surface_pred,"atp_surface_pred.csv")

new_wta<-wta_surface%>%
  dplyr::select(player0,player1,Surface)
predict(wta_random,type="response",newdata = new_wta)%>%
  as_tibble()->wta_pred
cbind(new_wta,colMeans(dplyr::select(df, starts_with('y_pred')))%>%
  as_tibble())->wta_surface_pred
#write_csv(wta_surface_pred,"wta_surface_pred.csv")
```


# Model Evaluation

After modeling the data, the predicted probability with each match will generate from different models. In addition,this project focuses on making probabilistic predictions on the overall outcome of each match. The predictions therefore take the form of a single value $$P_{w}$$, which is the probability assigned by a given model to the winning player. Since there are no draws and the probability of the losing player can be inferred as $$P_{l}=1-P_{w}$$, then a single value suffices for all predictions. For evaluating the model performances such as the model predictions are close to actual value or not, one of key method is the calibration. 

Calibration is a measure of the model accuracy and can be useful in order to better understand the behaviour and biases of different models. Basically, the probabilistic prediction can be well calibrated if the observed winning probability is close to $$\alpha$$ when considering all matches with predicted probabilities $$\alpha$$. In order to identify if this condition is satisfied, the calibration curve is established. Firstly,it group the data into 10 bins ordered by their predicted probability, 0-10%, 10-20%, etc and it calculated the mean predicted probability in each decile. And then sum of the matches of players win divided by the sum of the number of matches between each pair players played in each bin.

When a model is well-calibrated, the mean of actual probability against with mean of predictive probability will close with each other. If the mean of actual probability is greater than the mean of predictive probability, the models trend to be underestimate the wins of players, the reverse is overestimate.

##Bradley Terry Model

Table \@ref(tab:cali-BT-model) shows shows a plot of the calibration for 3 of the baseline models.

```{r cali-BT-model,fig.cap="Calibration table with Bradley Terry Model"}
atp_match%>%
  cbind(predict(atp_bt,type="response")%>%
  as_tibble())%>%
  rename(y_pred=value)%>%
  mutate(prob_p0=p0_count/total_count)->atp_bt_pred
wta_match%>%
  cbind(predict(wta_bt,type="response")%>%
  as_tibble())%>%
  rename(y_pred=value)%>%
  mutate(prob_p0=p0_count/total_count)->wta_bt_pred

bins<-function(data){
  data%>%
  mutate(bins=as.character(case_when(y_pred<=0.1~0.1,
                                     y_pred<=0.2&y_pred>0.1~0.2,
                                     y_pred<=0.3&y_pred>0.2~0.3,
                                     y_pred<=0.4&y_pred>0.3~0.4,
                                     y_pred<=0.5&y_pred>0.4~0.5,
                                     y_pred<=0.6&y_pred>0.5~0.6,
                                     y_pred<=0.7&y_pred>0.6~0.7,
                                     y_pred<=0.8&y_pred>0.7~0.8,
                                     y_pred<=0.9&y_pred>0.8~0.9,
                                     y_pred<=1&y_pred>0.9~1)))
}

bin_freq<-function(data){
  data%>%
  group_by(bins)%>%
  summarise(pred_prob=sum(y_pred))%>%
  left_join(data%>%
              group_by(bins)%>%
              tally())%>%
  mutate(mean_pred=pred_prob/n)%>%
  select(bins,mean_pred)
}

bins(atp_bt_pred)->atp_bt_bins
bin_freq(atp_bins)->atp_bt_freq


atp_bins%>%
  group_by(bins)%>%
  summarise(mean_act=sum(p0_count)/sum(total_count))%>%
  left_join(atp_bt_freq)->atp_cali
atp_cali%>%
  kable(caption = "Calibration table for ATP data") %>%
  kable_styling(bootstrap_options = 
                  c("striped", "condensed"), 
                  full_width = T, 
                  position = "center")

bins(wta_bt_pred)->wta_bt_bins
bin_freq(wta_bins)->wta_bt_freq


#final calibration table
wta_bins%>%
  group_by(bins)%>%
  summarise(mean_act=sum(p0_count)/sum(total_count))%>%
  left_join(atp_bt_freq)->wta_cali

wta_cali%>%
kable(caption = "Calibration table for WTA data") %>%
  kable_styling(bootstrap_options = 
                  c("striped", "condensed"), 
                  full_width = T, 
                  position = "center")
```

```{r cali-bt,fig.cap="Calibration curve in Bradley Terry Model}

ggplot(atp_cali,aes(mean_pred,mean_act))+
  geom_line()+
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  coord_cartesian(xlim = c(0, 1), ylim = c(0, 1)) +
  theme_bw()+
  xlab("Estimated probability")+ylab("Actual probability")+
  ggtitle("Calibration curve for ATP data")

ggplot(wta_cali,aes(mean_act,mean_pred))+
  geom_line()+
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  coord_cartesian(xlim = c(0, 1), ylim = c(0, 1)) +
  theme_bw()+
  xlab("Estimated probability")+ylab("Actual probability")+
  ggtitle("Calibration curve for WTA data")

```

